{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sinajahangir/ProbabilisticDL_Colab/blob/main/GaussianDL_Hydrology_v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Import libraries and read data"
      ],
      "metadata": {
        "id": "gKIs35un8lBC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "QxAZHMj8K366"
      },
      "outputs": [],
      "source": [
        "#import necessary libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import tensorflow_probability\n",
        "import os\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aZtQ3BGuK_61",
        "outputId": "377892b1-7b66-41d9-bd48-9d3005d4a67a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "x4Ic7pvRLDFw"
      },
      "outputs": [],
      "source": [
        "#change directory to where input data is saved\n",
        "os.chdir('/content/drive/MyDrive/CARD_Hydrology')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "SYHooUc7zwbZ"
      },
      "outputs": [],
      "source": [
        "#change path\n",
        "#train data\n",
        "csv_path='CamelsRegionaltrain_0_camels_01022500.csv'\n",
        "df = pd.read_csv(csv_path)\n",
        "df=df.dropna()\n",
        "#change path\n",
        "#test data\n",
        "csv_path_test='CamelsRegionaltest_0_camels_01022500.csv'\n",
        "df_test = pd.read_csv(csv_path_test)\n",
        "\n",
        "mean_=np.asarray(df.iloc[:,1:].mean())\n",
        "std_=np.asarray(df.iloc[:,1:].std())\n",
        "\n",
        "#transfrom data\n",
        "df_test_tr=df_test.iloc[:,1:]-mean_\n",
        "df_test_tr=df_test_tr/(std_)\n",
        "df_test_tr=df_test_tr.drop(columns=['basin_id'])\n",
        "df_test_tr['basin_id'] = df_test['basin_id']\n",
        "mean_q=df['q'].mean()\n",
        "std_q=df['q'].std()\n",
        "df_tr = df.iloc[:,1:].apply(lambda x: (x-x.mean())/(x.std()), axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#print transformed test data\n",
        "df_test_tr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "hba5ENQehlhE",
        "outputId": "0d287477-db5d-4d37-bc53-b4b5f6a75d6b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            pr      srad      tmax      tmin        vp         q  average_pr  \\\n",
              "0    -0.473552 -1.064105 -1.159628 -1.000030 -1.014460 -0.111022    0.000729   \n",
              "1    -0.473552 -1.070815 -0.673509 -0.507607 -0.712332 -0.174008    0.000729   \n",
              "2     2.399008 -1.552969 -0.363989  0.005664 -0.300331  0.275288    0.000729   \n",
              "3    -0.473552 -0.968504 -0.517799 -0.509593 -0.732651  0.628006    0.000729   \n",
              "4    -0.457161 -0.926131 -0.896630 -0.956347 -0.998872  0.502035    0.000729   \n",
              "...        ...       ...       ...       ...       ...       ...         ...   \n",
              "1508 -0.473552 -0.638121 -1.121650 -1.384239 -1.172488 -0.299978    0.000729   \n",
              "1509 -0.473552 -1.166944 -1.590678 -1.265105 -1.115442 -0.350367    0.000729   \n",
              "1510  0.519482 -1.309215 -0.976384 -0.793530 -0.900348 -0.299978    0.000729   \n",
              "1511 -0.133434 -1.048423 -0.797887 -0.828278 -0.921199 -0.249590    0.000729   \n",
              "1512 -0.473552 -0.537317 -1.760630 -2.070256 -1.388116 -0.346168    0.000729   \n",
              "\n",
              "      average_q  average_tmax  average_tmin  basin_id  \n",
              "0     -0.003809      0.006756      0.002457         0  \n",
              "1     -0.003809      0.006756      0.002457         0  \n",
              "2     -0.003809      0.006756      0.002457         0  \n",
              "3     -0.003809      0.006756      0.002457         0  \n",
              "4     -0.003809      0.006756      0.002457         0  \n",
              "...         ...           ...           ...       ...  \n",
              "1508  -0.003809      0.006756      0.002457         0  \n",
              "1509  -0.003809      0.006756      0.002457         0  \n",
              "1510  -0.003809      0.006756      0.002457         0  \n",
              "1511  -0.003809      0.006756      0.002457         0  \n",
              "1512  -0.003809      0.006756      0.002457         0  \n",
              "\n",
              "[1513 rows x 11 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-63bc29af-0d30-4138-a47b-a4cf73fad56f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pr</th>\n",
              "      <th>srad</th>\n",
              "      <th>tmax</th>\n",
              "      <th>tmin</th>\n",
              "      <th>vp</th>\n",
              "      <th>q</th>\n",
              "      <th>average_pr</th>\n",
              "      <th>average_q</th>\n",
              "      <th>average_tmax</th>\n",
              "      <th>average_tmin</th>\n",
              "      <th>basin_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.473552</td>\n",
              "      <td>-1.064105</td>\n",
              "      <td>-1.159628</td>\n",
              "      <td>-1.000030</td>\n",
              "      <td>-1.014460</td>\n",
              "      <td>-0.111022</td>\n",
              "      <td>0.000729</td>\n",
              "      <td>-0.003809</td>\n",
              "      <td>0.006756</td>\n",
              "      <td>0.002457</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.473552</td>\n",
              "      <td>-1.070815</td>\n",
              "      <td>-0.673509</td>\n",
              "      <td>-0.507607</td>\n",
              "      <td>-0.712332</td>\n",
              "      <td>-0.174008</td>\n",
              "      <td>0.000729</td>\n",
              "      <td>-0.003809</td>\n",
              "      <td>0.006756</td>\n",
              "      <td>0.002457</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.399008</td>\n",
              "      <td>-1.552969</td>\n",
              "      <td>-0.363989</td>\n",
              "      <td>0.005664</td>\n",
              "      <td>-0.300331</td>\n",
              "      <td>0.275288</td>\n",
              "      <td>0.000729</td>\n",
              "      <td>-0.003809</td>\n",
              "      <td>0.006756</td>\n",
              "      <td>0.002457</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.473552</td>\n",
              "      <td>-0.968504</td>\n",
              "      <td>-0.517799</td>\n",
              "      <td>-0.509593</td>\n",
              "      <td>-0.732651</td>\n",
              "      <td>0.628006</td>\n",
              "      <td>0.000729</td>\n",
              "      <td>-0.003809</td>\n",
              "      <td>0.006756</td>\n",
              "      <td>0.002457</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.457161</td>\n",
              "      <td>-0.926131</td>\n",
              "      <td>-0.896630</td>\n",
              "      <td>-0.956347</td>\n",
              "      <td>-0.998872</td>\n",
              "      <td>0.502035</td>\n",
              "      <td>0.000729</td>\n",
              "      <td>-0.003809</td>\n",
              "      <td>0.006756</td>\n",
              "      <td>0.002457</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1508</th>\n",
              "      <td>-0.473552</td>\n",
              "      <td>-0.638121</td>\n",
              "      <td>-1.121650</td>\n",
              "      <td>-1.384239</td>\n",
              "      <td>-1.172488</td>\n",
              "      <td>-0.299978</td>\n",
              "      <td>0.000729</td>\n",
              "      <td>-0.003809</td>\n",
              "      <td>0.006756</td>\n",
              "      <td>0.002457</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1509</th>\n",
              "      <td>-0.473552</td>\n",
              "      <td>-1.166944</td>\n",
              "      <td>-1.590678</td>\n",
              "      <td>-1.265105</td>\n",
              "      <td>-1.115442</td>\n",
              "      <td>-0.350367</td>\n",
              "      <td>0.000729</td>\n",
              "      <td>-0.003809</td>\n",
              "      <td>0.006756</td>\n",
              "      <td>0.002457</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1510</th>\n",
              "      <td>0.519482</td>\n",
              "      <td>-1.309215</td>\n",
              "      <td>-0.976384</td>\n",
              "      <td>-0.793530</td>\n",
              "      <td>-0.900348</td>\n",
              "      <td>-0.299978</td>\n",
              "      <td>0.000729</td>\n",
              "      <td>-0.003809</td>\n",
              "      <td>0.006756</td>\n",
              "      <td>0.002457</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1511</th>\n",
              "      <td>-0.133434</td>\n",
              "      <td>-1.048423</td>\n",
              "      <td>-0.797887</td>\n",
              "      <td>-0.828278</td>\n",
              "      <td>-0.921199</td>\n",
              "      <td>-0.249590</td>\n",
              "      <td>0.000729</td>\n",
              "      <td>-0.003809</td>\n",
              "      <td>0.006756</td>\n",
              "      <td>0.002457</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1512</th>\n",
              "      <td>-0.473552</td>\n",
              "      <td>-0.537317</td>\n",
              "      <td>-1.760630</td>\n",
              "      <td>-2.070256</td>\n",
              "      <td>-1.388116</td>\n",
              "      <td>-0.346168</td>\n",
              "      <td>0.000729</td>\n",
              "      <td>-0.003809</td>\n",
              "      <td>0.006756</td>\n",
              "      <td>0.002457</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1513 rows × 11 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-63bc29af-0d30-4138-a47b-a4cf73fad56f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-63bc29af-0d30-4138-a47b-a4cf73fad56f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-63bc29af-0d30-4138-a47b-a4cf73fad56f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c45e20a3-35fd-418d-a602-024e40973778\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c45e20a3-35fd-418d-a602-024e40973778')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c45e20a3-35fd-418d-a602-024e40973778 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_6d845ae9-bcaa-46e1-a80a-d60e910f6ac0\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_test_tr')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_6d845ae9-bcaa-46e1-a80a-d60e910f6ac0 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_test_tr');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_test_tr",
              "summary": "{\n  \"name\": \"df_test_tr\",\n  \"rows\": 1513,\n  \"fields\": [\n    {\n      \"column\": \"pr\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.1149968110201596,\n        \"min\": -0.47355185861232185,\n        \"max\": 11.696923496186272,\n        \"num_unique_values\": 545,\n        \"samples\": [\n          -0.16485068799677952,\n          -0.3902298612337905,\n          -0.2331474071595101\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"srad\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0111937510858489,\n        \"min\": -2.0527651010217336,\n        \"max\": 2.632230963300402,\n        \"num_unique_values\": 1488,\n        \"samples\": [\n          -0.7192462901354046,\n          0.34201965558947656,\n          0.08416731583534952\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tmax\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9661630276035014,\n        \"min\": -2.4233460510680604,\n        \"max\": 2.0457160762119786,\n        \"num_unique_values\": 1238,\n        \"samples\": [\n          0.4259540220076558,\n          0.3566441568511988,\n          1.1370922275170565\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tmin\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9909029826740436,\n        \"min\": -2.9568157041619427,\n        \"max\": 1.880048604203965,\n        \"num_unique_values\": 1207,\n        \"samples\": [\n          -0.8163642573563401,\n          1.2287795183484567,\n          1.3201160364867293\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"vp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.054346850874536,\n        \"min\": -1.533260132353689,\n        \"max\": 3.0914529392845527,\n        \"num_unique_values\": 1415,\n        \"samples\": [\n          0.3662970300367603,\n          2.0026441518100095,\n          0.39945944682736323\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"q\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.1694751498483325,\n        \"min\": -0.7618707710529498,\n        \"max\": 9.941437186676563,\n        \"num_unique_values\": 492,\n        \"samples\": [\n          1.4132228037229968,\n          0.3172779716447689,\n          2.11026051301413\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"average_pr\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 9.97795794033314e-18,\n        \"min\": 0.0007288204583484221,\n        \"max\": 0.0007288204583484221,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0007288204583484221\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"average_q\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7.80883664895637e-18,\n        \"min\": -0.003809301595634419,\n        \"max\": -0.003809301595634419,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          -0.003809301595634419\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"average_tmax\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.4923554484672174e-16,\n        \"min\": 0.006756362627392129,\n        \"max\": 0.006756362627392129,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.006756362627392129\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"average_tmin\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.121330453615862e-17,\n        \"min\": 0.0024568591372335015,\n        \"max\": 0.0024568591372335015,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0024568591372335015\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"basin_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Error Metrics"
      ],
      "metadata": {
        "id": "vEAFWWq3x9iZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Utebyb-tLbWe"
      },
      "outputs": [],
      "source": [
        "def nash_sutcliffe_error(Q_obs,Q_sim):\n",
        "    \"\"\"\n",
        "    Written by: SJ\n",
        "    Q_obs: observed discharge; 1D vector\n",
        "    Q_sim: simulated discharge; 1D vector\n",
        "    This function calculates the NSE between observed and simulated discharges\n",
        "    returns: NSE; float\n",
        "    \"\"\"\n",
        "    if len(Q_sim)!=len(Q_obs):\n",
        "        print('Length of simulated and observed discharges do not match')\n",
        "        return\n",
        "    else:\n",
        "        num=np.sum(np.square(Q_sim-Q_obs))\n",
        "        den=np.sum(np.square(Q_obs-np.mean(Q_obs)))\n",
        "        NSE=1-(num/den)\n",
        "        return NSE\n",
        "\n",
        "def CC(Pr,Y):\n",
        "    from scipy import stats\n",
        "    Pr=np.reshape(Pr,(-1,1))\n",
        "    Y=np.reshape(Y,(-1,1))\n",
        "    return stats.pearsonr(Pr.flatten(),Y.flatten())[0]\n",
        "def KGE(prediction,observation):\n",
        "\n",
        "    nas = np.logical_or(np.isnan(prediction), np.isnan(observation))\n",
        "    pred=np.copy(np.reshape(prediction,(-1,1)))\n",
        "    obs=np.copy(np.reshape(observation,(-1,1)))\n",
        "    r=CC(pred[~nas],obs[~nas])\n",
        "    beta=np.nanmean(pred)/np.nanmean(obs)\n",
        "    gamma=(np.nanstd(pred)/np.nanstd(obs))/beta\n",
        "    kge=1-((r-1)**2+(beta-1)**2+(gamma-1)**2)**0.5\n",
        "    return kge"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reshaping input data to 3D"
      ],
      "metadata": {
        "id": "RatM1E0b-Rxm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_sequence_multi_train(sequence_x,sequence_y, n_steps_in, n_steps_out,mode='seq'):\n",
        "    \"\"\"\n",
        "    written by:SJ\n",
        "    sequence_x=features; 2D array\n",
        "    sequence_y=target; 2D array\n",
        "    n_steps_in=IL(lookbak period);int\n",
        "    n_steps_out=forecast horizon;int\n",
        "    mode:either single (many to one) or seq (many to many).\n",
        "    This function creates an output in shape of (sample,IL,feature) for x and\n",
        "    (sample,n_steps_out) for y\n",
        "    \"\"\"\n",
        "    X, y = list(), list()\n",
        "    k=0\n",
        "    sequence_x=np.copy(np.asarray(sequence_x))\n",
        "    sequence_y=np.copy(np.asarray(sequence_y))\n",
        "    for _ in range(len(sequence_x)):\n",
        "\t\t# find the end of this pattern\n",
        "        end_ix = k + n_steps_in\n",
        "        out_end_ix = end_ix + n_steps_out\n",
        "\t\t# check if we are beyond the sequence\n",
        "        if out_end_ix > len(sequence_x):\n",
        "            break\n",
        "\t\t# gather input and output parts of the pattern\n",
        "        seq_x = sequence_x[k:end_ix]\n",
        "        #mode single is used for one output\n",
        "        if n_steps_out==0:\n",
        "            seq_y= sequence_y[end_ix-1:out_end_ix]\n",
        "        elif mode=='single':\n",
        "            seq_y= sequence_y[out_end_ix-1]\n",
        "        else:\n",
        "            seq_y= sequence_y[end_ix:out_end_ix]\n",
        "        X.append(seq_x)\n",
        "        y.append(seq_y.flatten())\n",
        "        k=k+1\n",
        "\n",
        "    XX,YY= np.asarray(X), np.asarray(y)\n",
        "    if (n_steps_out==0 or n_steps_out==1):\n",
        "        YY=YY.reshape((len(XX),1))\n",
        "    return XX,YY"
      ],
      "metadata": {
        "id": "7fOO074V-QuL"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ii=0\n",
        "temp_x=np.asarray(df_tr[df['basin_id']==ii].loc[:, ['pr', 'srad', 'tmax', 'tmin', 'vp', 'average_pr',\n",
        "           'average_q', 'average_tmax', 'average_tmin']])\n",
        "temp_y=np.asarray(df_tr[df['basin_id']==ii]['q']).reshape((-1,1))\n",
        "xx,yy=split_sequence_multi_train(temp_x,temp_y,365,0,mode='seq')\n",
        "\n",
        "\n",
        "\n",
        "x_train=xx[:int(0.9*len(xx))]\n",
        "y_train=yy[:int(0.9*len(xx))]\n",
        "\n",
        "x_val=xx[int(0.9*len(xx)):]\n",
        "y_val=yy[int(0.9*len(xx)):]"
      ],
      "metadata": {
        "id": "-h50f-9XyfEt"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Define the model"
      ],
      "metadata": {
        "id": "yRDRM2AT_Omi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: add a dense layer to the top of nn_without_head:inputs = tf.keras.layers.Input(shape=(365, 9))\n",
        "# x_ = tf.keras.layers.LSTM(128, return_sequences=False)(inputs)\n",
        "# x=tf.keras.layers.Dropout(0.1)(x_)\n",
        "# outputs = tf.keras.layers.Dense(1,activation='linear')(x)\n",
        "# #outputs=tf.keras.layers.Reshape((3,1),name='output')(outputs)\n",
        "# modeli = tf.keras.Model(inputs, outputs)\n",
        "# modeli.compile(optimizer=tf.optimizers.Adam(learning_rate=1e-3), loss=\"mse\")\n",
        "# modeli.load_weights('Final_sim_0.h5')\n",
        "# nn_without_head = tf.keras.models.Model(inputs=modeli.inputs, outputs=x_)\n",
        "\n",
        "# Add a dense layer to the top of nn_without_head\n",
        "dense_layer = tf.keras.layers.Dense(64, activation='relu')(nn_without_head.output)  # Example: 64 units, ReLU activation\n",
        "output_layer = tf.keras.layers.Dense(1, activation='linear')(dense_layer) # Output layer with linear activation\n",
        "new_model = tf.keras.models.Model(inputs=nn_without_head.input, outputs=output_layer)\n",
        "\n",
        "# Compile the new model\n",
        "new_model.compile(optimizer=tf.optimizers.Adam(learning_rate=1e-3), loss=\"mse\")\n",
        "\n",
        "# Print the new model summary to verify\n",
        "new_model.summary()"
      ],
      "metadata": {
        "id": "BRSbKXLrAjdX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tf.keras.layers.Input(shape=(365, 9))\n",
        "x_ = tf.keras.layers.LSTM(128, return_sequences=False)(inputs)\n",
        "x_.trainable=False\n",
        "x=tf.keras.layers.Dropout(0.1)(x_)\n",
        "outputs = tf.keras.layers.Dense(1,activation='linear')(x)\n",
        "#outputs=tf.keras.layers.Reshape((3,1),name='output')(outputs)\n",
        "modeli = tf.keras.Model(inputs, outputs)\n",
        "modeli.compile(optimizer=tf.optimizers.Adam(learning_rate=1e-3), loss=\"mse\")\n",
        "#load pre-trained model weights\n",
        "modeli.load_weights('Final_sim_0.h5')\n",
        "nn_without_head = tf.keras.models.Model(inputs=modeli.inputs, outputs=x_)\n",
        "nn_without_head.trainable=False\n"
      ],
      "metadata": {
        "id": "EbmQUJNK_UkE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def modeli_():\n",
        "    inputs = tf.keras.layers.Input(shape=(365, 9))\n",
        "    #input_dynamic=tf.keras.layers.Lambda(lambda x: x[:,:,:5])(inputs)\n",
        "    #input_static=tf.keras.layers.Lambda(lambda x: x[:,0,5:])(inputs)\n",
        "    #x=tf.keras.layers.Normalization(axis=-1)(inputs)\n",
        "    x = tf.keras.layers.LSTM(256, return_sequences=False)(inputs)\n",
        "    x=tf.keras.layers.Dropout(0.2)(x)\n",
        "    #x_=tf.keras.layers.Dense(256,activation='relu')(input_static)\n",
        "    #y=tf.keras.layers.Add()([x,x_])\n",
        "    outputs = tf.keras.layers.Dense(1,activation='linear')(x)\n",
        "    #outputs=tf.keras.layers.Reshape((3,1),name='output')(outputs)\n",
        "    model = tf.keras.Model(inputs, outputs)\n",
        "    model.compile(optimizer=tf.optimizers.Adam(learning_rate=1e-4), loss=\"mse\")\n",
        "    return model"
      ],
      "metadata": {
        "id": "uunt_bLS4yo8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_m=modeli_()\n",
        "model_m.load_weights('Final_sim_0.h5')"
      ],
      "metadata": {
        "id": "FFHKe-s95B9o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_m=model_m.predict(xx)\n",
        "x_mtrain=x_m[:int(0.9*len(xx))]\n",
        "x_mval=x_m[int(0.9*len(xx)):]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dsDdE-mn5XdB",
        "outputId": "81c6bf6c-9a1d-4518-c27c-3a1ef2a8c261"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m257/257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zurzghY6LqO_"
      },
      "outputs": [],
      "source": [
        "class GaussianDiffusion:\n",
        "    \"\"\"Gaussian diffusion utility.\n",
        "\n",
        "    Args:\n",
        "        beta_start: Start value of the scheduled variance\n",
        "        beta_end: End value of the scheduled variance\n",
        "        timesteps: Number of time steps in the forward process\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        beta_start=1e-4,\n",
        "        beta_end=0.02,\n",
        "        timesteps=1000,\n",
        "        clip_min=-1.0,\n",
        "        clip_max=1.0,\n",
        "        beta_type='linear',\n",
        "    ):\n",
        "        self.beta_start = beta_start\n",
        "        self.beta_end = beta_end\n",
        "\n",
        "        self.timesteps = timesteps\n",
        "\n",
        "        self.clip_min = clip_min\n",
        "        self.clip_max = clip_max\n",
        "\n",
        "        max_beta = beta_end\n",
        "        cosine_s = 0.008\n",
        "\n",
        "        # Define the variance schedule\n",
        "        if beta_type=='linear':\n",
        "          betas = np.linspace(\n",
        "              beta_start,\n",
        "              beta_end,\n",
        "              timesteps,\n",
        "              dtype=np.float64,  # Using float64 for better precision\n",
        "          )\n",
        "        elif beta_type=='cosine_anneal':\n",
        "          betas=np.asarray([beta_start + 0.5 * (beta_end - beta_start) * (1 - np.cos(iii / (timesteps - 1) * np.pi)) for iii in range(timesteps)])\n",
        "        elif beta_type=='cosine':\n",
        "          betas=np.asarray([min(1 - (np.cos(((iii + 1) / timesteps + cosine_s) / (1 + cosine_s) * np.pi / 2) ** 2) / (\n",
        "                    np.cos((iii / timesteps + cosine_s) / (1 + cosine_s) * np.pi / 2) ** 2), max_beta) for iii in\n",
        "             range(timesteps)])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        self.num_timesteps = int(timesteps)\n",
        "\n",
        "        alphas = 1.0 - betas\n",
        "        #cumulative product of alphas\n",
        "        #alpha bar\n",
        "        alphas_cumprod = np.cumprod(alphas, axis=0)\n",
        "        #alphabar_t-1\n",
        "        alphas_cumprod_prev = np.append(1.0, alphas_cumprod[:-1])\n",
        "\n",
        "        #convert to tensorflow format\n",
        "        self.betas = tf.constant(betas, dtype=tf.float32)\n",
        "        self.alphas_cumprod = tf.constant(alphas_cumprod, dtype=tf.float32)\n",
        "        self.alphas_cumprod_prev = tf.constant(alphas_cumprod_prev, dtype=tf.float32)\n",
        "\n",
        "        # Calculations for diffusion q(x_t | x_{t-1}) and others\n",
        "\n",
        "        #\n",
        "        self.sqrt_alphas_cumprod = tf.constant(\n",
        "            np.sqrt(alphas_cumprod), dtype=tf.float32\n",
        "        )\n",
        "\n",
        "        self.sqrt_one_minus_alphas_cumprod = tf.constant(\n",
        "            np.sqrt(1.0 - alphas_cumprod), dtype=tf.float32\n",
        "        )\n",
        "\n",
        "        self.one_minus_sqrt_alphas_cumprod = tf.constant(\n",
        "            np.sqrt(1.0 - np.sqrt(alphas_cumprod)), dtype=tf.float32\n",
        "        )\n",
        "\n",
        "        self.log_one_minus_alphas_cumprod = tf.constant(\n",
        "            np.log(1.0 - alphas_cumprod), dtype=tf.float32\n",
        "        )\n",
        "\n",
        "        self.sqrt_recip_alphas_cumprod = tf.constant(\n",
        "            np.sqrt(1.0 / alphas_cumprod), dtype=tf.float32\n",
        "        )\n",
        "\n",
        "        self.sqrt_recipm1_alphas_cumprod = tf.constant(\n",
        "            np.sqrt(1.0 / alphas_cumprod - 1), dtype=tf.float32\n",
        "        )\n",
        "\n",
        "        #For CARD\n",
        "        self.sqrt_recipm_alphas_cumprod_1 = tf.constant(\n",
        "            np.sqrt(1.0 / alphas_cumprod)-1, dtype=tf.float32\n",
        "        )\n",
        "\n",
        "        # Calculations for posterior q(x_{t-1} | x_t, x_0)\n",
        "        #Beta_tilda t\n",
        "        posterior_variance = (\n",
        "            betas * (1.0 - alphas_cumprod_prev) / (1.0 - alphas_cumprod)\n",
        "        )\n",
        "        #convert to tensorflow format\n",
        "        self.posterior_variance = tf.constant(posterior_variance, dtype=tf.float32)\n",
        "\n",
        "        # Log calculation clipped because the posterior variance is 0 at the beginning\n",
        "        # of the diffusion chain\n",
        "        self.posterior_log_variance_clipped = tf.constant(\n",
        "            np.log(np.maximum(posterior_variance, 1e-20)), dtype=tf.float32\n",
        "        )\n",
        "\n",
        "        # Coefficients for the mean (gamma_o)\n",
        "        self.posterior_mean_coef1 = tf.constant(\n",
        "            betas * np.sqrt(alphas_cumprod_prev) / (1.0 - alphas_cumprod),\n",
        "            dtype=tf.float32,\n",
        "        )\n",
        "\n",
        "        # Coefficients for the mean_2 (gamma_1)\n",
        "        self.posterior_mean_coef2 = tf.constant(\n",
        "            (1.0 - alphas_cumprod_prev) * np.sqrt(alphas) / (1.0 - alphas_cumprod),\n",
        "            dtype=tf.float32,\n",
        "        )\n",
        "\n",
        "        # Coefficients for the mean_3 (gamma_2)\n",
        "        #For CARD\n",
        "        self.posterior_mean_coef3 = tf.constant(\n",
        "            1.0 + (np.sqrt(alphas_cumprod)-1) * (np.sqrt(alphas)+np.sqrt(alphas_cumprod_prev)) / (1.0 - alphas_cumprod),\n",
        "            dtype=tf.float32,\n",
        "        )\n",
        "\n",
        "\n",
        "    def _extract(self, a, t, x_shape):\n",
        "        \"\"\"Extract some coefficients (e.g., alpha, beta) at specified timesteps,\n",
        "        then reshape to [batch_size, 1, 1, 1, 1, ...] for broadcasting purposes.\n",
        "\n",
        "        Args:\n",
        "            a: Tensor to extract from\n",
        "            t: Timestep for which the coefficients are to be extracted\n",
        "            t has the shape [batch_size]\n",
        "            x_shape: Shape of the current batched samples.\n",
        "        \"\"\"\n",
        "        batch_size = x_shape[0]\n",
        "        out = tf.gather(a, t)\n",
        "        return tf.reshape(out, [batch_size, 1])\n",
        "\n",
        "    def q_mean_variance(self, x_start,t,x_mean):\n",
        "        \"\"\"Extracts the mean, and the variance (plus log) at current timestep.\n",
        "\n",
        "        Args:\n",
        "            x_start: Initial sample (before the first diffusion step) (x_0)\n",
        "            t: Current timestep [batch_size]\n",
        "            q(x_t | x_0)\n",
        "        Returns:\n",
        "        \"\"\"\n",
        "        x_start_shape = tf.shape(x_start)\n",
        "        mean = self._extract(self.sqrt_alphas_cumprod, t, x_start_shape) * x_start+\\\n",
        "            self._extract(self.one_minus_sqrt_alphas_cumprod, t, x_start_shape)*x_mean\n",
        "        variance = self._extract(1.0 - self.alphas_cumprod, t, x_start_shape)\n",
        "        log_variance = self._extract(\n",
        "            self.log_one_minus_alphas_cumprod, t, x_start_shape\n",
        "        )\n",
        "        return mean, variance, log_variance\n",
        "\n",
        "    def q_sample(self, x_start, t, noise,x_mean):\n",
        "        \"\"\"Diffuse the data.\n",
        "        Get noisy data at timestep t\n",
        "\n",
        "        Args:\n",
        "            x_start: Initial sample (before the first diffusion step) (x_0)\n",
        "            t: Current timestep [batch_size]\n",
        "            noise: Gaussian noise to be added at the current timestep [tf.shape(x_0)]\n",
        "        Returns:\n",
        "            Diffused samples at timestep `t`\n",
        "            x_t = sqrt(alphabar_t) * x_0 + sqrt(1-alphabar_t)*noise+mean*(1-sqrt(alphabar_t))\n",
        "        \"\"\"\n",
        "        #get shape of the data (batch,....)\n",
        "        x_start_shape = tf.shape(x_start)\n",
        "\n",
        "        #CARD\n",
        "\n",
        "        return (\n",
        "            self._extract(self.sqrt_alphas_cumprod, t, x_start_shape) * x_start\n",
        "            + self._extract(self.sqrt_one_minus_alphas_cumprod, t, x_start_shape)* noise\n",
        "            + self._extract(self.one_minus_sqrt_alphas_cumprod, t, x_start_shape)*x_mean\n",
        "        )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        \"\"\"\n",
        "        return (\n",
        "            self._extract(self.sqrt_alphas_cumprod, t, x_start_shape) * x_start\n",
        "            + self._extract(self.sqrt_one_minus_alphas_cumprod, t, x_start_shape)\n",
        "            * noise\n",
        "        )\n",
        "        \"\"\"\n",
        "\n",
        "\n",
        "\n",
        "    def predict_start_from_noise(self, x_t, t, noise,x_mean):\n",
        "        #calculate estimate of the x_start. Reparamterization\n",
        "        #1/sqrt(alphabar_t)(x_t)-1/sqrt(alphabar_t)(sqrt(1-alphabar_t)*noise)-(1/sqrt(alphabar_t)-1)*x_mean\n",
        "        x_t_shape = tf.shape(x_t)\n",
        "\n",
        "        #CARD\n",
        "        return (\n",
        "            self._extract(self.sqrt_recip_alphas_cumprod, t, x_t_shape) * x_t\n",
        "            - self._extract(self.sqrt_recipm1_alphas_cumprod, t, x_t_shape) * noise\n",
        "        -self._extract(self.sqrt_recipm_alphas_cumprod_1, t, x_t_shape)*x_mean\n",
        "        )\n",
        "\n",
        "\n",
        "        \"\"\"\n",
        "        return (\n",
        "            self._extract(self.sqrt_recip_alphas_cumprod, t, x_t_shape) * x_t\n",
        "            - self._extract(self.sqrt_recipm1_alphas_cumprod, t, x_t_shape) * noise\n",
        "        )\n",
        "        \"\"\"\n",
        "\n",
        "\n",
        "    def q_posterior(self, x_start, x_t, t,x_mean):\n",
        "        \"\"\"Compute the mean and variance of the diffusion\n",
        "        posterior q(x_{t-1} | x_t, x_0).\n",
        "\n",
        "        Args:\n",
        "            x_start: Stating point(sample) for the posterior computation\n",
        "            x_t: Sample at timestep `t`\n",
        "            t: Current timestep\n",
        "        Returns:\n",
        "            Posterior mean and variance at current timestep\n",
        "        \"\"\"\n",
        "\n",
        "        x_t_shape = tf.shape(x_t)\n",
        "\n",
        "        #CARD\n",
        "        posterior_mean = (\n",
        "            self._extract(self.posterior_mean_coef1, t, x_t_shape) * x_start\n",
        "            + self._extract(self.posterior_mean_coef2, t, x_t_shape) * x_t\n",
        "        +self._extract(self.posterior_mean_coef3, t, x_t_shape) * x_mean)\n",
        "\n",
        "        \"\"\"\n",
        "        posterior_mean = (\n",
        "            self._extract(self.posterior_mean_coef1, t, x_t_shape) * x_start\n",
        "            + self._extract(self.posterior_mean_coef2, t, x_t_shape) * x_t\n",
        "        )\n",
        "        \"\"\"\n",
        "        #Beta_tilda t: self.posterior_variance\n",
        "        #only dependent on t\n",
        "        posterior_variance = self._extract(self.posterior_variance, t, x_t_shape)\n",
        "        posterior_log_variance_clipped = self._extract(\n",
        "            self.posterior_log_variance_clipped, t, x_t_shape\n",
        "        )\n",
        "        return posterior_mean, posterior_variance, posterior_log_variance_clipped\n",
        "\n",
        "    def p_mean_variance(self, pred_noise, x, t,x_mean, clip_denoised=True):\n",
        "        \"\"\"Compute the mean and variance of the diffusion\n",
        "        Args:\n",
        "            pred_noise: Noise predicted by the diffusion model\n",
        "            x: Samples at a given timestep for which the noise was predicted (x_t)\n",
        "            t: Current timestep\n",
        "            clip_denoised (bool): Whether to clip the predicted noise\n",
        "                within the specified range or not.\n",
        "        \"\"\"\n",
        "        #x_t-1\n",
        "        x_recon = self.predict_start_from_noise(x, t=t, noise=pred_noise,x_mean=x_mean)\n",
        "        #between min and max\n",
        "        if clip_denoised:\n",
        "            x_recon = tf.clip_by_value(x_recon, self.clip_min, self.clip_max)\n",
        "\n",
        "        model_mean, posterior_variance, posterior_log_variance = self.q_posterior(\n",
        "            x_start=x_recon, x_t=x, t=t,x_mean=x_mean)\n",
        "        #model mean= gamma_0*x_0,gamma_1*x_t+gamma_2*x_mean\n",
        "        return model_mean, posterior_variance, posterior_log_variance\n",
        "\n",
        "    def p_sample(self, pred_noise, x, t,x_mean=0, clip_denoised=True):\n",
        "        \"\"\"Sample from the diffusion model.\n",
        "\n",
        "        Args:\n",
        "            pred_noise: Noise predicted by the diffusion model at specific timestep\n",
        "            x: Samples at a given timestep for which the noise was predicted (x_t)\n",
        "            t: Current timestep [batch_size]\n",
        "            clip_denoised (bool): Whether to clip the predicted noise\n",
        "                within the specified range or not.\n",
        "        \"\"\"\n",
        "        model_mean, _, model_log_variance = self.p_mean_variance(\n",
        "            pred_noise, x=x, t=t, clip_denoised=clip_denoised,x_mean=x_mean\n",
        "        )\n",
        "        noise = tf.random.normal(shape=x.shape, dtype=x.dtype)\n",
        "        x_shape=tf.shape(x)\n",
        "        # No noise when t == 0\n",
        "        #[batch_size] + [1] * (len(x_shape) - 1)\n",
        "        nonzero_mask = tf.reshape(\n",
        "            1 - tf.cast(tf.equal(t, 0), tf.float32), [x_shape[0],1]\n",
        "        )\n",
        "\n",
        "        return model_mean + nonzero_mask * tf.exp(0.5 * model_log_variance) * noise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xXNgxm0RLvva"
      },
      "outputs": [],
      "source": [
        "def build_model(num_h_n,n_feature=1,activation_fn=keras.activations.swish,num_step=1000):\n",
        "    \"\"\"\n",
        "    Parameters\n",
        "    ----------\n",
        "    num_h_n : int\n",
        "        number hidden nodes.\n",
        "    activation_fn : string\n",
        "        activation function type.\n",
        "    n_feature : int\n",
        "        X feature size (for regression).\n",
        "    Returns\n",
        "    -------\n",
        "    tf object\n",
        "        A tf.keras model.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    #noisy target input\n",
        "    x_input = keras.Input(\n",
        "        shape=(n_feature,), name=\"x_input\")\n",
        "    #xt_input=tf.keras.layers.Flatten()(x_input)\n",
        "\n",
        "    #mean input\n",
        "    xm_input = keras.Input(\n",
        "        shape=(n_feature,), name=\"xm_input\")\n",
        "    #xmt_input=tf.keras.layers.Flatten()(xm_input)\n",
        "\n",
        "    #covariates_input\n",
        "    xx_input=keras.Input(\n",
        "        shape=(365,9), name=\"xx_input\")\n",
        "    xxt_input=tf.keras.layers.LSTM(32)(xx_input)\n",
        "\n",
        "    #time input\n",
        "    t_input = keras.Input(shape=(n_feature,), dtype=tf.int64, name=\"time_input\")\n",
        "    t_input=tf.keras.layers.Lambda(lambda x:x/10000)(t_input)\n",
        "\n",
        "    #dense layers\n",
        "    x_=keras.layers.Dense(units=num_h_n, activation=activation_fn,name='dense_x_0')(x_input)\n",
        "    x_m=keras.layers.Dense(units=num_h_n, activation=activation_fn,name='dense_xm_0')(xm_input)\n",
        "    t_=keras.layers.Dense(units=num_h_n, activation=activation_fn,name='dense_t_0')(t_input)\n",
        "    xx_=keras.layers.Dense(units=num_h_n, activation=activation_fn,name='dense_xx_0')(xxt_input)\n",
        "\n",
        "    x=tf.keras.layers.Lambda(lambda x:x[0]+x[1]+x[2]+x[3])([x_,x_m,t_,xx_])\n",
        "    x=tf.keras.layers.Dropout(0.2)(x)\n",
        "    x=tf.keras.layers.Dense(units=16, activation=activation_fn,name='dense_x_1')(x)\n",
        "    output = keras.layers.Dense(units=1, activation='linear')(x)\n",
        "\n",
        "\n",
        "    return keras.Model([x_input,xm_input, t_input,xx_input], output, name=\"CARD\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(num_h_n,n_feature=1,activation_fn=keras.activations.swish,num_step=1000):\n",
        "    \"\"\"\n",
        "    Parameters\n",
        "    ----------\n",
        "    num_h_n : int\n",
        "        number hidden nodes.\n",
        "    activation_fn : string\n",
        "        activation function type.\n",
        "    n_feature : int\n",
        "        X feature size (for regression).\n",
        "    Returns\n",
        "    -------\n",
        "    tf object\n",
        "        A tf.keras model.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    #noisy target input\n",
        "    x_input = keras.Input(\n",
        "        shape=(n_feature,), name=\"x_input\")\n",
        "    #xt_input=tf.keras.layers.Flatten()(x_input)\n",
        "\n",
        "    #mean input\n",
        "    xm_input = keras.Input(\n",
        "        shape=(n_feature,), name=\"xm_input\")\n",
        "    #xmt_input=tf.keras.layers.Flatten()(xm_input)\n",
        "\n",
        "    #covariates_input\n",
        "    xx_input=keras.Input(\n",
        "        shape=(365,9), name=\"xx_input\")\n",
        "    xxt_input=tf.keras.layers.LSTM(4)(xx_input)\n",
        "\n",
        "    #time input\n",
        "    t_input = keras.Input(shape=(n_feature,), dtype=tf.int64, name=\"time_input\")\n",
        "    t_input=tf.keras.layers.Lambda(lambda x:x/10000)(t_input)\n",
        "\n",
        "    #dense layers\n",
        "    x_=keras.layers.Dense(units=num_h_n, activation=activation_fn,name='dense_x_0')(x_input)\n",
        "    x_m=keras.layers.Dense(units=num_h_n, activation=activation_fn,name='dense_xm_0')(xm_input)\n",
        "    t_=keras.layers.Dense(units=num_h_n, activation=activation_fn,name='dense_t_0')(t_input)\n",
        "    xx_=keras.layers.Dense(units=num_h_n, activation=activation_fn,name='dense_xx_0')(xxt_input)\n",
        "\n",
        "    x=tf.keras.layers.Lambda(lambda x:x[0]+x[1]+x[2]+x[3])([x_,x_m,t_,xx_])\n",
        "    x=tf.keras.layers.Multiply()([x,xx_])\n",
        "    output = keras.layers.Dense(units=1, activation='linear')(x)\n",
        "\n",
        "    return keras.Model([x_input,xm_input, t_input,xx_input], output, name=\"CARD\")"
      ],
      "metadata": {
        "id": "GEzufgLL0Psf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SUz80hL-Lz34"
      },
      "outputs": [],
      "source": [
        "class DiffusionModel(keras.Model):\n",
        "    def __init__(self, network, ema_network, timesteps, gdf_util, ema=0.999):\n",
        "        super().__init__()\n",
        "        self.network = network\n",
        "        self.ema_network = ema_network\n",
        "        self.timesteps = timesteps\n",
        "        self.gdf_util = gdf_util\n",
        "        self.ema = ema\n",
        "\n",
        "    def train_step(self, data):\n",
        "        X,Y=data\n",
        "        x_0=X[0]\n",
        "        x_m=X[1]\n",
        "        x_x=X[2]\n",
        "\n",
        "        batch_size = tf.shape(x_0)[0]\n",
        "        # 2. Sample timesteps uniformly\n",
        "        t = tf.random.uniform(\n",
        "            minval=0, maxval=self.timesteps, shape=(batch_size,1),dtype=tf.dtypes.int32)\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            # 3. Sample random noise to be added to the images in the batch\n",
        "            noise = tf.random.normal(shape=(batch_size,1))\n",
        "\n",
        "            # 4. Diffuse the images with noise\n",
        "            x_t = self.gdf_util.q_sample(x_0, t, noise,x_m)\n",
        "\n",
        "            # 5. Pass the diffused images and time steps to the network\n",
        "            #Change so that x_mean is also given [x_t,t,x_mean]\n",
        "            pred_noise = self.network([x_t,x_m, t,x_x], training=True)\n",
        "\n",
        "            # 6. Calculate the loss\n",
        "            loss = self.loss(noise, pred_noise)\n",
        "\n",
        "        # 7. Get the gradients\n",
        "        gradients = tape.gradient(loss, self.network.trainable_weights)\n",
        "\n",
        "        # 8. Update the weights of the network\n",
        "        self.optimizer.apply_gradients(zip(gradients, self.network.trainable_weights))\n",
        "\n",
        "        # 9. Updates the weight values for the network with EMA weights\n",
        "        # Exponential moving average for smoother training\n",
        "        for weight, ema_weight in zip(self.network.weights, self.ema_network.weights):\n",
        "            ema_weight.assign(self.ema * ema_weight + (1 - self.ema) * weight)\n",
        "        # 10. Return loss values\n",
        "        return {\"loss\": loss}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AuGRirPNL3Ar",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32cea878-f729-4c8b-c936-86dd89120b10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - loss: 0.7120 - learning_rate: 0.0010\n",
            "Epoch 2/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.3644 - learning_rate: 0.0010\n",
            "Epoch 3/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.2440 - learning_rate: 0.0010\n",
            "Epoch 4/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.2336 - learning_rate: 0.0010\n",
            "Epoch 5/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.2222 - learning_rate: 0.0010\n",
            "Epoch 6/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.2017 - learning_rate: 0.0010\n",
            "Epoch 7/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.2198 - learning_rate: 0.0010\n",
            "Epoch 8/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.1903 - learning_rate: 0.0010\n",
            "Epoch 9/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.1925 - learning_rate: 0.0010\n",
            "Epoch 10/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.1778 - learning_rate: 0.0010\n",
            "Epoch 11/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.1733 - learning_rate: 0.0010\n",
            "Epoch 12/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.1688 - learning_rate: 0.0010\n",
            "Epoch 13/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.1901 - learning_rate: 0.0010\n",
            "Epoch 14/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.1619 - learning_rate: 0.0010\n",
            "Epoch 15/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.1621 - learning_rate: 0.0010\n",
            "Epoch 16/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.1592 - learning_rate: 0.0010\n",
            "Epoch 17/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.1513 - learning_rate: 0.0010\n",
            "Epoch 18/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.1564 - learning_rate: 0.0010\n",
            "Epoch 19/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.1501 - learning_rate: 0.0010\n",
            "Epoch 20/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.1483 - learning_rate: 0.0010\n",
            "Epoch 21/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.1500 - learning_rate: 0.0010\n",
            "Epoch 22/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.1472 - learning_rate: 0.0010\n",
            "Epoch 23/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.1386 - learning_rate: 0.0010\n",
            "Epoch 24/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.1396 - learning_rate: 0.0010\n",
            "Epoch 25/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.1392 - learning_rate: 0.0010\n",
            "Epoch 26/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.1337 - learning_rate: 0.0010\n",
            "Epoch 27/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.1383 - learning_rate: 0.0010\n",
            "Epoch 28/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.1377 - learning_rate: 0.0010\n",
            "Epoch 29/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.1320 - learning_rate: 0.0010\n",
            "Epoch 30/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.1265 - learning_rate: 0.0010\n",
            "Epoch 31/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.1227 - learning_rate: 0.0010\n",
            "Epoch 32/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.1316 - learning_rate: 0.0010\n",
            "Epoch 33/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.1277 - learning_rate: 0.0010\n",
            "Epoch 34/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.1347 - learning_rate: 0.0010\n",
            "Epoch 35/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.1590 - learning_rate: 0.0010\n",
            "Epoch 36/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.1244 - learning_rate: 0.0010\n",
            "Epoch 37/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.1346 - learning_rate: 0.0010\n",
            "Epoch 38/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.1249 - learning_rate: 0.0010\n",
            "Epoch 39/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.1289 - learning_rate: 0.0010\n",
            "Epoch 40/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.1232 - learning_rate: 0.0010\n",
            "Epoch 41/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.1176 - learning_rate: 0.0010\n",
            "Epoch 42/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.1283 - learning_rate: 0.0010\n",
            "Epoch 43/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.1205 - learning_rate: 0.0010\n",
            "Epoch 44/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.1211 - learning_rate: 0.0010\n",
            "Epoch 45/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.1214 - learning_rate: 0.0010\n",
            "Epoch 46/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.1131 - learning_rate: 0.0010\n",
            "Epoch 47/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.1041 - learning_rate: 0.0010\n",
            "Epoch 48/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.1090 - learning_rate: 0.0010\n",
            "Epoch 49/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.1035 - learning_rate: 0.0010\n",
            "Epoch 50/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.1033 - learning_rate: 0.0010\n",
            "Epoch 51/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.1029 - learning_rate: 0.0010\n",
            "Epoch 52/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0998 - learning_rate: 5.0000e-04\n",
            "Epoch 53/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.1046 - learning_rate: 5.0000e-04\n",
            "Epoch 54/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.1148 - learning_rate: 5.0000e-04\n",
            "Epoch 55/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.1026 - learning_rate: 5.0000e-04\n",
            "Epoch 56/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0980 - learning_rate: 5.0000e-04\n",
            "Epoch 57/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0974 - learning_rate: 5.0000e-04\n",
            "Epoch 58/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0949 - learning_rate: 5.0000e-04\n",
            "Epoch 59/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0971 - learning_rate: 5.0000e-04\n",
            "Epoch 60/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0926 - learning_rate: 5.0000e-04\n",
            "Epoch 61/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0901 - learning_rate: 5.0000e-04\n",
            "Epoch 62/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0933 - learning_rate: 5.0000e-04\n",
            "Epoch 63/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0945 - learning_rate: 5.0000e-04\n",
            "Epoch 64/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0959 - learning_rate: 5.0000e-04\n",
            "Epoch 65/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0946 - learning_rate: 5.0000e-04\n",
            "Epoch 66/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0973 - learning_rate: 5.0000e-04\n",
            "Epoch 67/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0931 - learning_rate: 5.0000e-04\n",
            "Epoch 68/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0889 - learning_rate: 5.0000e-04\n",
            "Epoch 69/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0923 - learning_rate: 5.0000e-04\n",
            "Epoch 70/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0902 - learning_rate: 5.0000e-04\n",
            "Epoch 71/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0939 - learning_rate: 5.0000e-04\n",
            "Epoch 72/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0892 - learning_rate: 5.0000e-04\n",
            "Epoch 73/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0916 - learning_rate: 5.0000e-04\n",
            "Epoch 74/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0862 - learning_rate: 5.0000e-04\n",
            "Epoch 75/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0864 - learning_rate: 5.0000e-04\n",
            "Epoch 76/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0926 - learning_rate: 5.0000e-04\n",
            "Epoch 77/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0911 - learning_rate: 5.0000e-04\n",
            "Epoch 78/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0893 - learning_rate: 5.0000e-04\n",
            "Epoch 79/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0946 - learning_rate: 5.0000e-04\n",
            "Epoch 80/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0926 - learning_rate: 5.0000e-04\n",
            "Epoch 81/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0880 - learning_rate: 5.0000e-04\n",
            "Epoch 82/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0826 - learning_rate: 5.0000e-04\n",
            "Epoch 83/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0831 - learning_rate: 5.0000e-04\n",
            "Epoch 84/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0840 - learning_rate: 5.0000e-04\n",
            "Epoch 85/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0867 - learning_rate: 5.0000e-04\n",
            "Epoch 86/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0859 - learning_rate: 5.0000e-04\n",
            "Epoch 87/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0847 - learning_rate: 5.0000e-04\n",
            "Epoch 88/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0851 - learning_rate: 5.0000e-04\n",
            "Epoch 89/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0851 - learning_rate: 5.0000e-04\n",
            "Epoch 90/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0859 - learning_rate: 5.0000e-04\n",
            "Epoch 91/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0906 - learning_rate: 5.0000e-04\n",
            "Epoch 92/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0847 - learning_rate: 5.0000e-04\n",
            "Epoch 93/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0804 - learning_rate: 5.0000e-04\n",
            "Epoch 94/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0796 - learning_rate: 5.0000e-04\n",
            "Epoch 95/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0787 - learning_rate: 5.0000e-04\n",
            "Epoch 96/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0837 - learning_rate: 5.0000e-04\n",
            "Epoch 97/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0814 - learning_rate: 5.0000e-04\n",
            "Epoch 98/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0838 - learning_rate: 5.0000e-04\n",
            "Epoch 99/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0863 - learning_rate: 5.0000e-04\n",
            "Epoch 100/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0845 - learning_rate: 5.0000e-04\n",
            "Epoch 101/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0786 - learning_rate: 5.0000e-04\n",
            "Epoch 102/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0778 - learning_rate: 2.5000e-04\n",
            "Epoch 103/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0764 - learning_rate: 2.5000e-04\n",
            "Epoch 104/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0767 - learning_rate: 2.5000e-04\n",
            "Epoch 105/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0788 - learning_rate: 2.5000e-04\n",
            "Epoch 106/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0715 - learning_rate: 2.5000e-04\n",
            "Epoch 107/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0779 - learning_rate: 2.5000e-04\n",
            "Epoch 108/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0767 - learning_rate: 2.5000e-04\n",
            "Epoch 109/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0729 - learning_rate: 2.5000e-04\n",
            "Epoch 110/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0720 - learning_rate: 2.5000e-04\n",
            "Epoch 111/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0697 - learning_rate: 2.5000e-04\n",
            "Epoch 112/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0765 - learning_rate: 2.5000e-04\n",
            "Epoch 113/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0728 - learning_rate: 2.5000e-04\n",
            "Epoch 114/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0700 - learning_rate: 2.5000e-04\n",
            "Epoch 115/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0713 - learning_rate: 2.5000e-04\n",
            "Epoch 116/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0693 - learning_rate: 2.5000e-04\n",
            "Epoch 117/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0747 - learning_rate: 2.5000e-04\n",
            "Epoch 118/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0723 - learning_rate: 2.5000e-04\n",
            "Epoch 119/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0714 - learning_rate: 2.5000e-04\n",
            "Epoch 120/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0782 - learning_rate: 2.5000e-04\n",
            "Epoch 121/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0766 - learning_rate: 2.5000e-04\n",
            "Epoch 122/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0732 - learning_rate: 2.5000e-04\n",
            "Epoch 123/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0695 - learning_rate: 2.5000e-04\n",
            "Epoch 124/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0776 - learning_rate: 2.5000e-04\n",
            "Epoch 125/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0723 - learning_rate: 2.5000e-04\n",
            "Epoch 126/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0731 - learning_rate: 2.5000e-04\n",
            "Epoch 127/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0690 - learning_rate: 2.5000e-04\n",
            "Epoch 128/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0827 - learning_rate: 2.5000e-04\n",
            "Epoch 129/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0780 - learning_rate: 2.5000e-04\n",
            "Epoch 130/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0704 - learning_rate: 2.5000e-04\n",
            "Epoch 131/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0695 - learning_rate: 2.5000e-04\n",
            "Epoch 132/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0729 - learning_rate: 2.5000e-04\n",
            "Epoch 133/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0777 - learning_rate: 2.5000e-04\n",
            "Epoch 134/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0695 - learning_rate: 2.5000e-04\n",
            "Epoch 135/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0677 - learning_rate: 2.5000e-04\n",
            "Epoch 136/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0705 - learning_rate: 2.5000e-04\n",
            "Epoch 137/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0676 - learning_rate: 2.5000e-04\n",
            "Epoch 138/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0683 - learning_rate: 2.5000e-04\n",
            "Epoch 139/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0754 - learning_rate: 2.5000e-04\n",
            "Epoch 140/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0747 - learning_rate: 2.5000e-04\n",
            "Epoch 141/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0722 - learning_rate: 2.5000e-04\n",
            "Epoch 142/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0732 - learning_rate: 2.5000e-04\n",
            "Epoch 143/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0856 - learning_rate: 2.5000e-04\n",
            "Epoch 144/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0803 - learning_rate: 2.5000e-04\n",
            "Epoch 145/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0739 - learning_rate: 2.5000e-04\n",
            "Epoch 146/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0686 - learning_rate: 2.5000e-04\n",
            "Epoch 147/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0681 - learning_rate: 2.5000e-04\n",
            "Epoch 148/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0670 - learning_rate: 2.5000e-04\n",
            "Epoch 149/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0670 - learning_rate: 2.5000e-04\n",
            "Epoch 150/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0711 - learning_rate: 2.5000e-04\n",
            "Epoch 151/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0711 - learning_rate: 2.5000e-04\n",
            "Epoch 152/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0677 - learning_rate: 1.2500e-04\n",
            "Epoch 153/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0683 - learning_rate: 1.2500e-04\n",
            "Epoch 154/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0708 - learning_rate: 1.2500e-04\n",
            "Epoch 155/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0673 - learning_rate: 1.2500e-04\n",
            "Epoch 156/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0694 - learning_rate: 1.2500e-04\n",
            "Epoch 157/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0687 - learning_rate: 1.2500e-04\n",
            "Epoch 158/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0677 - learning_rate: 1.2500e-04\n",
            "Epoch 159/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0675 - learning_rate: 1.2500e-04\n",
            "Epoch 160/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0648 - learning_rate: 1.2500e-04\n",
            "Epoch 161/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0666 - learning_rate: 1.2500e-04\n",
            "Epoch 162/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0651 - learning_rate: 1.2500e-04\n",
            "Epoch 163/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0679 - learning_rate: 1.2500e-04\n",
            "Epoch 164/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0700 - learning_rate: 1.2500e-04\n",
            "Epoch 165/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0634 - learning_rate: 1.2500e-04\n",
            "Epoch 166/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0705 - learning_rate: 1.2500e-04\n",
            "Epoch 167/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0672 - learning_rate: 1.2500e-04\n",
            "Epoch 168/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0722 - learning_rate: 1.2500e-04\n",
            "Epoch 169/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0723 - learning_rate: 1.2500e-04\n",
            "Epoch 170/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0688 - learning_rate: 1.2500e-04\n",
            "Epoch 171/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0669 - learning_rate: 1.2500e-04\n",
            "Epoch 172/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0634 - learning_rate: 1.2500e-04\n",
            "Epoch 173/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0641 - learning_rate: 1.2500e-04\n",
            "Epoch 174/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0697 - learning_rate: 1.2500e-04\n",
            "Epoch 175/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0634 - learning_rate: 1.2500e-04\n",
            "Epoch 176/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0637 - learning_rate: 1.2500e-04\n",
            "Epoch 177/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0656 - learning_rate: 1.2500e-04\n",
            "Epoch 178/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0663 - learning_rate: 1.2500e-04\n",
            "Epoch 179/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0655 - learning_rate: 1.2500e-04\n",
            "Epoch 180/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0686 - learning_rate: 1.2500e-04\n",
            "Epoch 181/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0701 - learning_rate: 1.2500e-04\n",
            "Epoch 182/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0645 - learning_rate: 1.2500e-04\n",
            "Epoch 183/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0708 - learning_rate: 1.2500e-04\n",
            "Epoch 184/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0678 - learning_rate: 1.2500e-04\n",
            "Epoch 185/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0643 - learning_rate: 1.2500e-04\n",
            "Epoch 186/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0634 - learning_rate: 1.2500e-04\n",
            "Epoch 187/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0612 - learning_rate: 1.2500e-04\n",
            "Epoch 188/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0649 - learning_rate: 1.2500e-04\n",
            "Epoch 189/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0629 - learning_rate: 1.2500e-04\n",
            "Epoch 190/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0659 - learning_rate: 1.2500e-04\n",
            "Epoch 191/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0627 - learning_rate: 1.2500e-04\n",
            "Epoch 192/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0652 - learning_rate: 1.2500e-04\n",
            "Epoch 193/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0673 - learning_rate: 1.2500e-04\n",
            "Epoch 194/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0801 - learning_rate: 1.2500e-04\n",
            "Epoch 195/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0627 - learning_rate: 1.2500e-04\n",
            "Epoch 196/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0652 - learning_rate: 1.2500e-04\n",
            "Epoch 197/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0636 - learning_rate: 1.2500e-04\n",
            "Epoch 198/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0676 - learning_rate: 1.2500e-04\n",
            "Epoch 199/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0664 - learning_rate: 1.2500e-04\n",
            "Epoch 200/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0668 - learning_rate: 1.2500e-04\n",
            "Epoch 201/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0647 - learning_rate: 1.2500e-04\n",
            "Epoch 202/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0650 - learning_rate: 6.2500e-05\n",
            "Epoch 203/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0641 - learning_rate: 6.2500e-05\n",
            "Epoch 204/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0628 - learning_rate: 6.2500e-05\n",
            "Epoch 205/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0614 - learning_rate: 6.2500e-05\n",
            "Epoch 206/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0637 - learning_rate: 6.2500e-05\n",
            "Epoch 207/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0634 - learning_rate: 6.2500e-05\n",
            "Epoch 208/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0616 - learning_rate: 6.2500e-05\n",
            "Epoch 209/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0624 - learning_rate: 6.2500e-05\n",
            "Epoch 210/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0635 - learning_rate: 6.2500e-05\n",
            "Epoch 211/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0670 - learning_rate: 6.2500e-05\n",
            "Epoch 212/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0684 - learning_rate: 6.2500e-05\n",
            "Epoch 213/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0673 - learning_rate: 6.2500e-05\n",
            "Epoch 214/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0609 - learning_rate: 6.2500e-05\n",
            "Epoch 215/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0632 - learning_rate: 6.2500e-05\n",
            "Epoch 216/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0622 - learning_rate: 6.2500e-05\n",
            "Epoch 217/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0617 - learning_rate: 6.2500e-05\n",
            "Epoch 218/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0645 - learning_rate: 6.2500e-05\n",
            "Epoch 219/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0844 - learning_rate: 6.2500e-05\n",
            "Epoch 220/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0632 - learning_rate: 6.2500e-05\n",
            "Epoch 221/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0601 - learning_rate: 6.2500e-05\n",
            "Epoch 222/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0593 - learning_rate: 6.2500e-05\n",
            "Epoch 223/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0616 - learning_rate: 6.2500e-05\n",
            "Epoch 224/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0612 - learning_rate: 6.2500e-05\n",
            "Epoch 225/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0611 - learning_rate: 6.2500e-05\n",
            "Epoch 226/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0622 - learning_rate: 6.2500e-05\n",
            "Epoch 227/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0641 - learning_rate: 6.2500e-05\n",
            "Epoch 228/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0601 - learning_rate: 6.2500e-05\n",
            "Epoch 229/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0602 - learning_rate: 6.2500e-05\n",
            "Epoch 230/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0595 - learning_rate: 6.2500e-05\n",
            "Epoch 231/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0646 - learning_rate: 6.2500e-05\n",
            "Epoch 232/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0647 - learning_rate: 6.2500e-05\n",
            "Epoch 233/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0598 - learning_rate: 6.2500e-05\n",
            "Epoch 234/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0614 - learning_rate: 6.2500e-05\n",
            "Epoch 235/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0633 - learning_rate: 6.2500e-05\n",
            "Epoch 236/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0585 - learning_rate: 6.2500e-05\n",
            "Epoch 237/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0628 - learning_rate: 6.2500e-05\n",
            "Epoch 238/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0618 - learning_rate: 6.2500e-05\n",
            "Epoch 239/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0637 - learning_rate: 6.2500e-05\n",
            "Epoch 240/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0627 - learning_rate: 6.2500e-05\n",
            "Epoch 241/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0600 - learning_rate: 6.2500e-05\n",
            "Epoch 242/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0595 - learning_rate: 6.2500e-05\n",
            "Epoch 243/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0647 - learning_rate: 6.2500e-05\n",
            "Epoch 244/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0590 - learning_rate: 6.2500e-05\n",
            "Epoch 245/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0633 - learning_rate: 6.2500e-05\n",
            "Epoch 246/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0634 - learning_rate: 6.2500e-05\n",
            "Epoch 247/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0652 - learning_rate: 6.2500e-05\n",
            "Epoch 248/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0611 - learning_rate: 6.2500e-05\n",
            "Epoch 249/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0605 - learning_rate: 6.2500e-05\n",
            "Epoch 250/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0627 - learning_rate: 6.2500e-05\n",
            "Epoch 251/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0605 - learning_rate: 6.2500e-05\n",
            "Epoch 252/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0644 - learning_rate: 3.1250e-05\n",
            "Epoch 253/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0607 - learning_rate: 3.1250e-05\n",
            "Epoch 254/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0659 - learning_rate: 3.1250e-05\n",
            "Epoch 255/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0598 - learning_rate: 3.1250e-05\n",
            "Epoch 256/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0610 - learning_rate: 3.1250e-05\n",
            "Epoch 257/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0593 - learning_rate: 3.1250e-05\n",
            "Epoch 258/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0628 - learning_rate: 3.1250e-05\n",
            "Epoch 259/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0635 - learning_rate: 3.1250e-05\n",
            "Epoch 260/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0599 - learning_rate: 3.1250e-05\n",
            "Epoch 261/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0617 - learning_rate: 3.1250e-05\n",
            "Epoch 262/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0580 - learning_rate: 3.1250e-05\n",
            "Epoch 263/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0594 - learning_rate: 3.1250e-05\n",
            "Epoch 264/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0610 - learning_rate: 3.1250e-05\n",
            "Epoch 265/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0611 - learning_rate: 3.1250e-05\n",
            "Epoch 266/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0590 - learning_rate: 3.1250e-05\n",
            "Epoch 267/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0624 - learning_rate: 3.1250e-05\n",
            "Epoch 268/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0599 - learning_rate: 3.1250e-05\n",
            "Epoch 269/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0613 - learning_rate: 3.1250e-05\n",
            "Epoch 270/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0644 - learning_rate: 3.1250e-05\n",
            "Epoch 271/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0590 - learning_rate: 3.1250e-05\n",
            "Epoch 272/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0603 - learning_rate: 3.1250e-05\n",
            "Epoch 273/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0608 - learning_rate: 3.1250e-05\n",
            "Epoch 274/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0615 - learning_rate: 3.1250e-05\n",
            "Epoch 275/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0639 - learning_rate: 3.1250e-05\n",
            "Epoch 276/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0666 - learning_rate: 3.1250e-05\n",
            "Epoch 277/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0636 - learning_rate: 3.1250e-05\n",
            "Epoch 278/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0584 - learning_rate: 3.1250e-05\n",
            "Epoch 279/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0594 - learning_rate: 3.1250e-05\n",
            "Epoch 280/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0598 - learning_rate: 3.1250e-05\n",
            "Epoch 281/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0598 - learning_rate: 3.1250e-05\n",
            "Epoch 282/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0610 - learning_rate: 3.1250e-05\n",
            "Epoch 283/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0608 - learning_rate: 3.1250e-05\n",
            "Epoch 284/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0605 - learning_rate: 3.1250e-05\n",
            "Epoch 285/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0615 - learning_rate: 3.1250e-05\n",
            "Epoch 286/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0612 - learning_rate: 3.1250e-05\n",
            "Epoch 287/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0589 - learning_rate: 3.1250e-05\n",
            "Epoch 288/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0605 - learning_rate: 3.1250e-05\n",
            "Epoch 289/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0615 - learning_rate: 3.1250e-05\n",
            "Epoch 290/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0608 - learning_rate: 3.1250e-05\n",
            "Epoch 291/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0611 - learning_rate: 3.1250e-05\n",
            "Epoch 292/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0606 - learning_rate: 3.1250e-05\n",
            "Epoch 293/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0584 - learning_rate: 3.1250e-05\n",
            "Epoch 294/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0582 - learning_rate: 3.1250e-05\n",
            "Epoch 295/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0597 - learning_rate: 3.1250e-05\n",
            "Epoch 296/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0600 - learning_rate: 3.1250e-05\n",
            "Epoch 297/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0612 - learning_rate: 3.1250e-05\n",
            "Epoch 298/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0612 - learning_rate: 3.1250e-05\n",
            "Epoch 299/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0580 - learning_rate: 3.1250e-05\n",
            "Epoch 300/300\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0619 - learning_rate: 3.1250e-05\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7f53d7dae080>"
            ]
          },
          "metadata": {},
          "execution_count": 186
        }
      ],
      "source": [
        "#%%\n",
        "num_epochs = 300\n",
        "# Build the unet model\n",
        "total_timesteps=10\n",
        "network = build_model(num_h_n=256,num_step=total_timesteps)\n",
        "ema_network = build_model(num_h_n=256,num_step=total_timesteps)\n",
        "ema_network.set_weights(network.get_weights())  # Initially the weights are the same\n",
        "learning_rate = 1e-3\n",
        "batch_size=256\n",
        "\n",
        "\n",
        "# Get an instance of the Gaussian Diffusion utilities\n",
        "gdf_util = GaussianDiffusion(timesteps=total_timesteps,beta_type='linear',beta_start=1e-1,beta_end=0,clip_max=100)\n",
        "\n",
        "# Get the model\n",
        "model = DiffusionModel(\n",
        "    network=network,\n",
        "    ema_network=ema_network,\n",
        "    gdf_util=gdf_util,\n",
        "    timesteps=total_timesteps,\n",
        "    ema=0.1\n",
        ")\n",
        "\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    loss=keras.losses.MeanSquaredError(),\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
        ")\n",
        "\n",
        "callback_plat=tf.keras.callbacks.ReduceLROnPlateau(\n",
        "    monitor='loss',\n",
        "    factor=0.5,\n",
        "    patience=50,\n",
        "    verbose=0,\n",
        "    mode='auto',\n",
        "    min_delta=0.0001,\n",
        "    cooldown=0,\n",
        "    min_lr=1e-5,\n",
        ")\n",
        "\n",
        "callback_early = tf.keras.callbacks.EarlyStopping(monitor='loss',\n",
        "                                                    patience=20,\n",
        "                                                    restore_best_weights=False,\n",
        "                                                    mode='auto')\n",
        "# Train the model\n",
        "model.fit(\n",
        "    x=[yy,x_m,xx],\n",
        "    y=yy,\n",
        "    epochs=num_epochs,\n",
        "    batch_size=batch_size,\n",
        "    callbacks=[callback_plat]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "brcUgn4TTsx1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.network.save('DiffuseHydro_v1.keras')"
      ],
      "metadata": {
        "id": "kKjY3v8qvKgk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ii=0\n",
        "temp_xx=np.asarray(df_test_tr[df_test_tr['basin_id']==ii].loc[:, ['pr', 'srad', 'tmax', 'tmin', 'vp', 'average_pr',\n",
        "            'average_q', 'average_tmax', 'average_tmin']])\n",
        "temp_yy=np.asarray(df_test_tr[df_test_tr['basin_id']==ii]['q']).reshape((-1,1))\n",
        "xx_,yy_=split_sequence_multi_train(temp_xx,temp_yy,365,0,mode='seq')"
      ],
      "metadata": {
        "id": "Gv0RBftiCtxY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xx_m_=model_m.predict(xx_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_-RxTZJD-Ug",
        "outputId": "024e314f-f32e-4d30-a4ae-bebaf716bdb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "caMLUNaFMIad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d6ffb75-577a-45b9-d447-61eec3b98832"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n"
          ]
        }
      ],
      "source": [
        "model_ema_trained=model.network\n",
        "list_=[]\n",
        "#%%\n",
        "#Sample from the model iteratively\n",
        "for ii in range(0,10):\n",
        "  samples= tf.random.normal(\n",
        "            shape=(len(xx_), 1), dtype=tf.float32)\n",
        "  for t in reversed(range(0, total_timesteps)):\n",
        "      tt = tf.cast(tf.fill(len(xx_), t), dtype=tf.int64)\n",
        "      pred_noise = model_ema_trained.predict(\n",
        "          [samples,xx_m_, tt,xx_])\n",
        "      samples = gdf_util.p_sample(\n",
        "                  pred_noise, samples, tt,xx_m_, clip_denoised=True)\n",
        "  list_.append(samples)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def RMSE(Pr,Y):\n",
        "    Pr=np.reshape(Pr,(-1,1))\n",
        "    Y=np.reshape(Y,(-1,1))\n",
        "    rmse=(np.nanmean(((Pr-Y)**2)))**0.5\n",
        "    return rmse\n",
        "def reliability_quantile(observation,up_percentile,low_percentile):\n",
        "    width=np.nanmean(up_percentile-low_percentile)\n",
        "    id_1=observation<=up_percentile\n",
        "    id_2=id_1[observation>=low_percentile]\n",
        "    total_id=id_2\n",
        "    temp_len=np.nansum(total_id)\n",
        "    return temp_len/len(observation)*100,width"
      ],
      "metadata": {
        "id": "D-26l3ovHj1h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def nash(Q_obs,Q_sim):\n",
        "    \"\"\"\n",
        "    Written by: SJ\n",
        "    Q_obs: observed discharge; 1D vector\n",
        "    Q_sim: simulated discharge; 1D vector\n",
        "    This function calculates the NSE between observed and simulated discharges\n",
        "    returns: NSE; float\n",
        "    \"\"\"\n",
        "    if len(Q_sim)!=len(Q_obs):\n",
        "        print('Length of simulated and observed discharges do not match')\n",
        "        return\n",
        "    else:\n",
        "        num=np.sum(np.square(Q_sim-Q_obs))\n",
        "        den=np.sum(np.square(Q_obs-np.mean(Q_obs)))\n",
        "        NSE=1-(num/den)\n",
        "        return NSE"
      ],
      "metadata": {
        "id": "2VYwrm-4IgkB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#%%\n",
        "array_total=np.asarray(list_)\n",
        "median=np.median(array_total,axis=0)\n",
        "up=np.percentile(array_total,95,axis=0)\n",
        "down=np.percentile(array_total,5,axis=0)\n",
        "samples_array=np.asarray(median)\n",
        "\n",
        "\n",
        "\n",
        "target=yy_*std_q+mean_q\n",
        "pred_=median*std_q+mean_q\n",
        "pred_low=down*std_q+mean_q\n",
        "pred_up=up*std_q+mean_q\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "picp,width=reliability_quantile(target,pred_up,pred_low)\n",
        "nse_pred=nash(target,pred_)\n",
        "\n",
        "\n",
        "#%%\n",
        "plt.plot(pred_,'k',zorder=4,label='Diff pred')\n",
        "plt.plot(target,'b',zorder=3,label='obs')\n",
        "#plt.plot(mean_,'green',zorder=2)\n",
        "plt.fill_between(np.arange(len(pred_)),pred_low.ravel(),pred_up.ravel(),color='r',alpha=0.4,zorder=1)\n",
        "plt.title('PICP:%1.2f;'%(picp)+ 'NSE:%1.2f'%(nse_pred))\n",
        "plt.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "id": "BAvIHylnHpDg",
        "outputId": "8c1b6509-da81-4970-afd7-954164b31e7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f53d4ae62c0>"
            ]
          },
          "metadata": {},
          "execution_count": 190
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyM3NT4QzWX89rmSILXGBmaD",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}